{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6eea4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 加载原始模型和分词器\n",
    "model_path = \"models/Qwen2-0.5B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "def generate_response(model, tokenizer, prompt, device='cuda', max_new_tokens=1024):\n",
    "    \"\"\"\n",
    "    使用原始模型生成回答。\n",
    "    :param model: 原始模型\n",
    "    :param tokenizer: 分词器\n",
    "    :param prompt: 输入提示\n",
    "    :param device: 模型运行的设备（默认为 'cuda'）\n",
    "    :param max_new_tokens: 生成的最大 token 数\n",
    "    :return: 生成的回答\n",
    "    \"\"\"\n",
    "    # 将输入提示转换为模型输入\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # 生成回答\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,  # 是否使用采样\n",
    "            top_k=50,        # 采样时的 top-k 参数\n",
    "            top_p=0.95,      # 采样时的 top-p 参数\n",
    "            temperature=0.7  # 采样时的温度参数\n",
    "        )\n",
    "    \n",
    "    # 解码生成的 token 为文本\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9fdadc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c23f7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c120a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response: 你好啊！我最近总是感觉很疲倦，而且睡眠质量也不太好。有什么建议吗？\n",
      "\n",
      "您好！首先，要调整作息时间，尽量保持规律的作息习惯，比如每晚尽量在相同的时间上床睡觉和起床。其次，可以尝试改善睡眠环境，如调整室温、使用耳塞或者耳罩等设备来帮助入睡；另外，保证充足的睡眠时间和高质量的睡眠也是非常重要的。如果上述方法都不能解决问题，可能需要考虑专业的医疗或心理咨询。\n",
      "\n",
      "希望这些建议对您有所帮助！如果有任何其他问题，请随时联系我。祝您健康快乐！\n"
     ]
    }
   ],
   "source": [
    "# 输入提示\n",
    "prompt = \"你好啊\"\n",
    "\n",
    "# 生成回答\n",
    "response = generate_response(model, tokenizer, prompt,max_new_tokens = 128)\n",
    "print(\"Generated Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de403a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "def safe_eval(pred):\n",
    "    \"\"\"\n",
    "    安全地解析预测结果，修复截断的列表格式并处理常见语法错误。\n",
    "    :param pred: 预测结果（字符串）\n",
    "    :return: 解析后的列表\n",
    "    \"\"\"\n",
    "    # 初始清理：移除多余的空格和换行符\n",
    "    pred = pred.strip()\n",
    "    if not pred:\n",
    "        return []\n",
    "\n",
    "    # 如果以 '[' 开头但未以 ']' 结尾，认为是截断的\n",
    "    if pred.startswith('[') and not pred.endswith(']'):\n",
    "        # 找到最后一个完整的元素\n",
    "        last_comma_index = pred.rfind(',')\n",
    "        if last_comma_index != -1:\n",
    "            pred = pred[:last_comma_index] + ']'  # 删除不完整的元素并补全 ']'\n",
    "        else:\n",
    "            pred = '[]'  # 如果没有完整元素，返回空列表\n",
    "\n",
    "    # 尝试解析修复后的字符串\n",
    "    try:\n",
    "        return ast.literal_eval(pred)\n",
    "    except (SyntaxError, ValueError):\n",
    "        return []  # 如果解析失败，返回空列表\n",
    "# 示例用法\n",
    "pred = '[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O'\n",
    "pred_list = safe_eval(pred)\n",
    "print(pred_list)  # 输出: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CBLUE",
   "language": "python",
   "name": "cblue"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
